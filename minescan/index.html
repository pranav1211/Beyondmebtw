<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Real-time Mobile Document Scanner</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 10px;
      max-width: 100vw;
      margin: 0;
      background: #f5f5f5;
    }

    .container {
      max-width: 500px;
      margin: 0 auto;
      background: white;
      border-radius: 10px;
      overflow: hidden;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }

    .status {
      padding: 15px;
      margin: 15px;
      border-radius: 8px;
      font-weight: 500;
      text-align: center;
    }

    .status.loading {
      background: #fff3cd;
      border: 1px solid #ffeaa7;
      color: #856404;
    }

    .status.ready {
      background: #d1edff;
      border: 1px solid #bee5eb;
      color: #0c5460;
    }

    .status.detecting {
      background: #d4edda;
      border: 1px solid #c3e6cb;
      color: #155724;
    }

    .camera-section {
      padding: 20px;
      text-align: center;
    }

    #videoContainer {
      position: relative;
      background: #000;
      border-radius: 12px;
      overflow: hidden;
      margin-bottom: 20px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
    }

    #videoElement {
      width: 100%;
      height: auto;
      display: block;
    }

    #overlayCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }

    .camera-controls {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 20px;
      padding: 0 20px;
    }

    .btn {
      padding: 12px 20px;
      border: none;
      border-radius: 25px;
      font-size: 15px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }

    .btn-primary {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
    }

    .btn-success {
      background: linear-gradient(135deg, #56ab2f 0%, #a8e6cf 100%);
      color: white;
      flex: 1;
      margin: 0 10px;
      max-width: 200px;
    }

    .btn-secondary {
      background: #6c757d;
      color: white;
    }

    .btn:disabled {
      background: #ccc;
      cursor: not-allowed;
      transform: none;
      box-shadow: none;
    }

    .results-section {
      padding: 20px;
      display: none;
    }

    .image-container {
      margin-bottom: 20px;
    }

    .image-container h3 {
      margin-bottom: 10px;
      color: #333;
    }

    .image-container canvas {
      width: 100%;
      border: 1px solid #ddd;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }

    pre {
      background: #f8f9fa;
      padding: 10px;
      border-radius: 8px;
      white-space: pre-wrap;
      color: #333;
      font-size: 14px;
      max-height: 300px;
      overflow-y: auto;
    }

    .fps-counter {
      position: absolute;
      top: 10px;
      right: 10px;
      background: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 5px 10px;
      border-radius: 15px;
      font-size: 12px;
      font-weight: bold;
    }

    .processing-indicator {
      text-align: center;
      padding: 20px;
      display: none;
    }

    .processing-steps {
      margin: 10px 0;
      font-size: 14px;
      color: #666;
    }

    .step {
      margin: 5px 0;
    }

    .step.active {
      color: #28a745;
      font-weight: bold;
    }
  </style>
</head>

<body>
  <div class="container">
    <div id="statusMessage" class="status loading">Loading OpenCV and jscanify... Please wait.</div>

    <div class="camera-section" id="cameraSection" style="display:none;">
      <div id="videoContainer">
        <video id="videoElement" autoplay playsinline></video>
        <canvas id="overlayCanvas"></canvas>
        <div id="fpsCounter" class="fps-counter">0 FPS</div>
      </div>

      <div class="camera-controls">
        <button id="flashToggleBtn" class="btn btn-secondary" disabled>üí° Flash Off</button>
        <button id="captureBtn" class="btn btn-success" disabled>üì∏ Capture Document</button>
      </div>
    </div>

    <div class="processing-indicator" id="processingIndicator">
      <div style="color: #666; margin-bottom: 15px;">üîÑ Processing document...</div>
      <div class="processing-steps">
        <div class="step" id="step1">üì∑ Capturing image...</div>
        <div class="step" id="step2">üìÑ Extracting document...</div>
        <div class="step" id="step3">üîß Enhancing image...</div>
        <div class="step" id="step4">üîç Performing OCR...</div>
      </div>
    </div>

    <div class="results-section" id="resultsSection">
      <div class="image-container">
        <h3>üìÑ Extracted & Enhanced Document</h3>
        <canvas id="resultCanvas"></canvas>
        <div id="perfMetric" style="text-align: center; margin-top: 10px; color: #666; font-size: 14px;"></div>
      </div>
      <div class="image-container">
        <h3>üìù OCR Result</h3>
        <pre id="ocrResult">No text extracted yet.</pre>
      </div>
      <div style="text-align: center; margin-top: 20px;">
        <button id="newScanBtn" class="btn btn-primary">üì∑ New Scan</button>
      </div>
    </div>
  </div>

  <script>
    let scanner, lastImage = null, videoStream = null;
    let flashOn = false, imageCapture = null;
    let overlayCanvas, overlayCtx, video;
    let frameCount = 0, lastFpsTime = 0;
    let detectionLoop = null;
    let tesseractWorker = null; // Pre-initialize Tesseract worker

    // Custom document detection for grid overlay only
    class GridDetector {
      constructor() {
        this.initialized = false;
      }

      init() {
        if (typeof cv !== 'undefined') {
          this.initialized = true;
          return true;
        }
        return false;
      }

      detectDocument(canvas) {
        if (!this.initialized) return null;

        try {
          const src = cv.imread(canvas);
          const gray = new cv.Mat();
          const blur = new cv.Mat();
          const edges = new cv.Mat();
          const contours = new cv.MatVector();
          const hierarchy = new cv.Mat();

          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
          cv.GaussianBlur(gray, blur, new cv.Size(5, 5), 0);
          cv.Canny(blur, edges, 75, 200);
          cv.findContours(edges, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);

          let bestContour = null;
          let maxArea = 0;

          for (let i = 0; i < contours.size(); i++) {
            const contour = contours.get(i);
            const area = cv.contourArea(contour);

            if (area > 1000) {
              const peri = cv.arcLength(contour, true);
              const approx = new cv.Mat();
              cv.approxPolyDP(contour, approx, 0.02 * peri, true);

              if (approx.rows === 4 && area > maxArea) {
                maxArea = area;
                if (bestContour) bestContour.delete();
                bestContour = approx.clone();
              }
              approx.delete();
            }
          }

          src.delete(); gray.delete(); blur.delete(); edges.delete();
          contours.delete(); hierarchy.delete();

          return bestContour;
        } catch (err) {
          console.error('Grid detection error:', err);
          return null;
        }
      }

      getCornerPoints(contour) {
        if (!contour || contour.rows !== 4) return null;

        const points = [];
        for (let i = 0; i < 4; i++) {
          const point = contour.data32S.slice(i * 2, i * 2 + 2);
          points.push({ x: point[0], y: point[1] });
        }

        points.sort((a, b) => a.y - b.y);
        const top = points.slice(0, 2).sort((a, b) => a.x - b.x);
        const bottom = points.slice(2, 4).sort((a, b) => a.x - b.x);

        return [top[0], top[1], bottom[1], bottom[0]];
      }
    }

    const detector = new GridDetector();

    function updateStatus(message, type = 'loading') {
      const el = document.getElementById('statusMessage');
      el.textContent = message;
      el.className = `status ${type}`;
    }

    function updateProcessingStep(stepId) {
      // Clear all active steps
      document.querySelectorAll('.step').forEach(step => step.classList.remove('active'));
      // Set current step as active
      document.getElementById(stepId).classList.add('active');
    }

    // Pre-initialize Tesseract worker for faster OCR
    async function initTesseractWorker() {
      try {
        tesseractWorker = await Tesseract.createWorker('eng', 1, {
          logger: m => console.log(m),
          errorHandler: err => console.error(err)
        });
        
        await tesseractWorker.setParameters({
          tessedit_pageseg_mode: Tesseract.PSM.AUTO,
          tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,!?@#$%^&*()_+-=[]{}|;:\'",.<>/? \n'
        });
        
        console.log('Tesseract worker initialized');
      } catch (err) {
        console.error('Failed to initialize Tesseract worker:', err);
      }
    }

    async function onOpenCvReady() {
      try {
        window.cv = await window.cv;
        updateStatus("OpenCV ready. Loading jscanify...", 'ready');

        // Initialize Tesseract worker in parallel
        initTesseractWorker();

        // Load jscanify from CDN
        const script = document.createElement("script");
        script.src = "https://cdn.jsdelivr.net/gh/ColonelParrot/jscanify@master/src/jscanify.min.js";
        script.onload = async () => {
          scanner = new jscanify();
          detector.init();
          await startCamera();
          startGridDetection();
          updateStatus("Ready! Grid detection active.", 'detecting');
          document.getElementById("cameraSection").style.display = "block";
          document.getElementById("captureBtn").disabled = false;
        };
        script.onerror = () => updateStatus("Failed to load jscanify.js from CDN");
        document.head.appendChild(script);
      } catch (err) {
        updateStatus("Initialization failed: " + err);
      }
    }

    function setupOverlay() {
      video = document.getElementById('videoElement');
      overlayCanvas = document.getElementById('overlayCanvas');
      overlayCtx = overlayCanvas.getContext('2d');

      video.addEventListener('loadedmetadata', () => {
        overlayCanvas.width = video.videoWidth;
        overlayCanvas.height = video.videoHeight;
      });
    }

    function startGridDetection() {
      const processFrame = () => {
        try {
          const tempCanvas = document.createElement('canvas');
          const tempCtx = tempCanvas.getContext('2d');
          tempCanvas.width = video.videoWidth;
          tempCanvas.height = video.videoHeight;

          tempCtx.drawImage(video, 0, 0);

          const contour = detector.detectDocument(tempCanvas);

          overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

          if (contour) {
            const points = detector.getCornerPoints(contour);
            if (points && points.length === 4) {
              const scaleX = overlayCanvas.width / tempCanvas.width;
              const scaleY = overlayCanvas.height / tempCanvas.height;

              overlayCtx.strokeStyle = 'lime';
              overlayCtx.lineWidth = 4;
              overlayCtx.shadowBlur = 10;
              overlayCtx.shadowColor = 'black';

              overlayCtx.beginPath();
              overlayCtx.moveTo(points[0].x * scaleX, points[0].y * scaleY);
              for (let i = 1; i < 4; i++) {
                overlayCtx.lineTo(points[i].x * scaleX, points[i].y * scaleY);
              }
              overlayCtx.closePath();
              overlayCtx.stroke();

              overlayCtx.fillStyle = 'red';
              overlayCtx.shadowBlur = 5;
              points.forEach(point => {
                overlayCtx.beginPath();
                overlayCtx.arc(point.x * scaleX, point.y * scaleY, 8, 0, 2 * Math.PI);
                overlayCtx.fill();
              });
            }
            contour.delete();
          }

          frameCount++;
          const now = performance.now();
          if (now - lastFpsTime >= 1000) {
            document.getElementById('fpsCounter').textContent = `${frameCount} FPS`;
            frameCount = 0;
            lastFpsTime = now;
          }

        } catch (err) {
          console.error('Frame processing error:', err);
        }

        detectionLoop = requestAnimationFrame(processFrame);
      };

      processFrame();
    }

    async function startCamera() {
      try {
        if (videoStream) videoStream.getTracks().forEach(track => track.stop());

        const constraints = {
          video: {
            facingMode: 'environment',
            width: { ideal: 1280 },
            height: { ideal: 720 }
          }
        };

        videoStream = await navigator.mediaDevices.getUserMedia(constraints);
        video = document.getElementById('videoElement');
        video.srcObject = videoStream;

        setupOverlay();

        const [track] = videoStream.getVideoTracks();
        if (track.getCapabilities().torch) {
          imageCapture = new ImageCapture(track);
          document.getElementById("flashToggleBtn").disabled = false;
        }
      } catch (err) {
        alert("Camera error: " + err);
      }
    }

    document.getElementById("flashToggleBtn").addEventListener("click", async () => {
      if (!imageCapture) return;
      flashOn = !flashOn;
      try {
        await imageCapture.track.applyConstraints({ advanced: [{ torch: flashOn }] });
        document.getElementById("flashToggleBtn").textContent = flashOn ? "üí° Flash On" : "üí° Flash Off";
      } catch (err) {
        console.error("Flash toggle failed:", err);
      }
    });

    function enhanceDocumentForOCR(canvas, contrastFactor = 0.5, threshold = 160) {
      if (!cv) return canvas;

      try {
        const src = cv.imread(canvas);
        let processed = new cv.Mat();

        // Convert to grayscale
        cv.cvtColor(src, processed, cv.COLOR_RGBA2GRAY);

        // Apply lighter Gaussian blur to reduce noise and small artifacts
        let blurred = new cv.Mat();
        cv.GaussianBlur(processed, blurred, new cv.Size(5, 5), 0);

        // Enhance contrast using CLAHE
        let clahe = new cv.CLAHE(contrastFactor, new cv.Size(8, 8));
        clahe.apply(blurred, processed);

        // Apply adaptive thresholding with larger block size
        let thresholded = new cv.Mat();
        cv.adaptiveThreshold(processed, thresholded, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 15, 3);

        // Remove small noise (black dots) using opening with larger kernel
        let denoiseKernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, new cv.Size(2, 2));
        let denoised = new cv.Mat();
        cv.morphologyEx(thresholded, denoised, cv.MORPH_OPEN, denoiseKernel);

        // Light closing to connect broken character parts without merging characters
        let connectKernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, new cv.Size(1, 1));
        let final = new cv.Mat();
        cv.morphologyEx(denoised, final, cv.MORPH_CLOSE, connectKernel);

        // Additional noise removal - remove very small connected components (dots)
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(final, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
        
        // Create mask to remove small components
        let mask = cv.Mat.zeros(final.rows, final.cols, cv.CV_8UC1);
        mask.setTo(new cv.Scalar(255)); // Start with white background
        
        for (let i = 0; i < contours.size(); i++) {
          let contour = contours.get(i);
          let area = cv.contourArea(contour);
          
          // Remove very small components (likely noise dots)
          if (area < 20) {
            cv.drawContours(mask, contours, i, new cv.Scalar(0), -1);
          }
        }
        
        // Apply mask to remove small dots
        let cleaned = new cv.Mat();
        cv.bitwise_and(final, mask, cleaned);

        // Convert back to RGBA for display
        let result = new cv.Mat();
        cv.cvtColor(cleaned, result, cv.COLOR_GRAY2RGBA);

        const resultCanvas = document.createElement('canvas');
        cv.imshow(resultCanvas, result);

        // Cleanup
        src.delete(); processed.delete(); blurred.delete();
        thresholded.delete(); denoised.delete(); final.delete(); cleaned.delete(); result.delete(); 
        denoiseKernel.delete(); connectKernel.delete(); mask.delete();
        contours.delete(); hierarchy.delete(); clahe.delete();

        return resultCanvas;
      } catch (err) {
        console.error('Enhancement error:', err);
        return canvas;
      }
    }

    async function processDocument(imageData) {
      const t0 = performance.now();

      try {
        updateProcessingStep('step1');
        
        // Create image from data
        const img = new Image();
        return new Promise((resolve, reject) => {
          img.onload = async () => {
            try {
              const t1 = performance.now();
              updateProcessingStep('step2');
              
              // Use jscanify to extract the document with smaller output size for speed
              const extractedCanvas = scanner.extractPaper(img, 600, 800); // Reduced from 800x1200
              
              const t2 = performance.now();
              updateProcessingStep('step3');

              // Enhance the extracted document for OCR
              const enhancedCanvas = enhanceDocumentForOCR(extractedCanvas);

              // Display result
              const outCanvas = document.getElementById("resultCanvas");
              outCanvas.width = enhancedCanvas.width;
              outCanvas.height = enhancedCanvas.height;
              outCanvas.getContext("2d").drawImage(enhancedCanvas, 0, 0);

              const t3 = performance.now();
              updateProcessingStep('step4');

              // Perform OCR
              await performOCR(enhancedCanvas);

              const t4 = performance.now();
              
              // Display complete processing time
              document.getElementById("perfMetric").textContent = 
                `Total Processing Time: ${(t4 - t0).toFixed(0)} ms | ` +
                `Extraction: ${(t2 - t1).toFixed(0)} ms | ` +
                `Enhancement: ${(t3 - t2).toFixed(0)} ms | ` +
                `OCR: ${(t4 - t3).toFixed(0)} ms`;

              resolve();
            } catch (err) {
              reject(err);
            }
          };
          img.onerror = reject;
          img.src = imageData;
        });
      } catch (err) {
        throw err;
      }
    }

    async function captureAndProcess() {
      // Show processing indicator
      document.getElementById("processingIndicator").style.display = "block";
      document.getElementById("captureBtn").disabled = true;

      try {
        // Capture current frame with smaller resolution for speed
        const canvas = document.createElement("canvas");
        const ctx = canvas.getContext("2d");
        
        // Reduce capture size for faster processing
        const scale = Math.min(1280 / video.videoWidth, 720 / video.videoHeight, 1);
        canvas.width = video.videoWidth * scale;
        canvas.height = video.videoHeight * scale;
        
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        const capturedImageData = canvas.toDataURL('image/jpeg', 0.9); // Use JPEG with compression

        await processDocument(capturedImageData);

        // Show results
        document.getElementById("resultsSection").style.display = "block";
        document.getElementById("processingIndicator").style.display = "none";

      } catch (err) {
        console.error('Processing error:', err);
        document.getElementById("processingIndicator").style.display = "none";
        alert('Failed to process document. Please try again.');
      }

      document.getElementById("captureBtn").disabled = false;
    }

    async function performOCR(canvas) {
      try {
        let result;
        
        if (tesseractWorker) {
          // Use pre-initialized worker for faster OCR
          result = await tesseractWorker.recognize(canvas);
        } else {
          // Fallback to regular Tesseract if worker not available
          result = await Tesseract.recognize(canvas, 'eng', {
            logger: m => console.log(m),
            tessedit_pageseg_mode: Tesseract.PSM.AUTO
          });
        }
        
        const text = result.data.text;
        document.getElementById("ocrResult").textContent = text.trim() || "No text found.";
      } catch (err) {
        document.getElementById("ocrResult").textContent = "‚ö†Ô∏è OCR failed.";
        console.error(err);
      }
    }

    function newScan() {
      document.getElementById("resultsSection").style.display = "none";
      document.getElementById("ocrResult").textContent = "No text extracted yet.";
      document.getElementById("processingIndicator").style.display = "none";
      // Clear processing steps
      document.querySelectorAll('.step').forEach(step => step.classList.remove('active'));
    }

    // Event listeners
    document.getElementById("captureBtn").addEventListener("click", captureAndProcess);
    document.getElementById("newScanBtn").addEventListener("click", newScan);

    // Cleanup on page unload
    window.addEventListener('beforeunload', () => {
      if (detectionLoop) {
        cancelAnimationFrame(detectionLoop);
      }
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop());
      }
      if (tesseractWorker) {
        tesseractWorker.terminate();
      }
    });
  </script>

  <script src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5.0.4/dist/tesseract.min.js"></script>
</body>

</html>