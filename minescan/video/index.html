<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Real-time Mobile Document Scanner</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 10px;
      max-width: 100vw;
      margin: 0;
      background: #f5f5f5;
    }
    .container {
      max-width: 500px;
      margin: 0 auto;
      background: white;
      border-radius: 10px;
      overflow: hidden;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }
    .status {
      padding: 15px;
      margin: 15px;
      border-radius: 8px;
      font-weight: 500;
      text-align: center;
    }
    .status.loading {
      background: #fff3cd;
      border: 1px solid #ffeaa7;
      color: #856404;
    }
    .status.ready {
      background: #d1edff;
      border: 1px solid #bee5eb;
      color: #0c5460;
    }
    .status.detecting {
      background: #d4edda;
      border: 1px solid #c3e6cb;
      color: #155724;
    }
    .camera-section {
      padding: 20px;
      text-align: center;
    }
    #videoContainer {
      position: relative;
      background: #000;
      border-radius: 12px;
      overflow: hidden;
      margin-bottom: 20px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
    }
    #videoElement {
      width: 100%;
      height: auto;
      display: block;
    }
    #overlayCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    .camera-controls {
      display: flex;
      gap: 15px;
      justify-content: center;
      flex-wrap: wrap;
      margin-bottom: 20px;
    }
    .btn {
      padding: 12px 20px;
      border: none;
      border-radius: 25px;
      font-size: 15px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    .btn-primary {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
    }
    .btn-success {
      background: linear-gradient(135deg, #56ab2f 0%, #a8e6cf 100%);
      color: white;
    }
    .btn-secondary {
      background: #6c757d;
      color: white;
    }
    .btn-warning {
      background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
      color: white;
    }
    .btn:disabled {
      background: #ccc;
      cursor: not-allowed;
      transform: none;
      box-shadow: none;
    }
    .detection-toggle {
      margin-bottom: 15px;
    }
    .file-upload {
      margin-top: 20px;
      padding: 20px;
      border-top: 2px dashed #ddd;
    }
    .results-section {
      padding: 20px;
      display: none;
    }
    .image-container {
      margin-bottom: 20px;
    }
    .image-container h3 {
      margin-bottom: 10px;
      color: #333;
    }
    .image-container img,
    .image-container canvas {
      width: 100%;
      border: 1px solid #ddd;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    pre {
      background: #f8f9fa;
      padding: 10px;
      border-radius: 8px;
      white-space: pre-wrap;
      color: #333;
      font-size: 14px;
    }
    .fps-counter {
      position: absolute;
      top: 10px;
      right: 10px;
      background: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 5px 10px;
      border-radius: 15px;
      font-size: 12px;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <div class="container">
    <div id="statusMessage" class="status loading">Loading OpenCV... Please wait.</div>

    <div class="camera-section" id="cameraSection" style="display:none;">
      <div id="videoContainer">
        <video id="videoElement" autoplay playsinline></video>
        <canvas id="overlayCanvas"></canvas>
        <div id="fpsCounter" class="fps-counter">0 FPS</div>
      </div>

      <div class="detection-toggle">
        <button id="detectionToggle" class="btn btn-warning" disabled>üîç Start Detection</button>
      </div>

      <div class="camera-controls">
        <button id="captureBtn" class="btn btn-success" disabled>üì∏ Capture</button>
        <button id="flashToggleBtn" class="btn btn-secondary" disabled>üí° Flash Off</button>
      </div>

      <div class="file-upload">
        <input type="file" id="fileInput" accept="image/*" disabled />
        <p style="margin: 10px 0 0 0; color: #666; font-size: 14px;">Or select an image file</p>
      </div>
    </div>

    <div class="results-section" id="resultsSection">
      <div class="image-container">
        <h3>üìÑ Captured Image</h3>
        <img id="originalImage" alt="Original" />
      </div>
      <div class="image-container">
        <h3>‚ú® Enhanced + Detected Document</h3>
        <canvas id="resultCanvas"></canvas>
        <button id="reprocessBtn" class="btn btn-secondary" disabled>üîÑ Reprocess</button>
        <div id="perfMetric"></div>
      </div>
      <div class="image-container">
        <h3>üìù OCR Result</h3>
        <pre id="ocrResult">No text extracted yet.</pre>
      </div>
      <div style="text-align: center; margin-top: 20px;">
        <button id="newScanBtn" class="btn btn-primary">üì∑ New Scan</button>
      </div>
    </div>
  </div>

  <script>
    let scanner, lastImage = null, videoStream = null, currentCamera = 'environment';
    let flashOn = false, imageCapture = null;
    let isDetecting = false, detectionLoop = null;
    let overlayCanvas, overlayCtx, video;
    let frameCount = 0, lastFpsTime = 0;

    // Custom document detection using OpenCV
    class CustomDocumentDetector {
      constructor() {
        this.initialized = false;
      }

      init() {
        if (typeof cv !== 'undefined') {
          this.initialized = true;
          return true;
        }
        return false;
      }

      detectDocument(canvas) {
        if (!this.initialized) return null;

        try {
          const src = cv.imread(canvas);
          const gray = new cv.Mat();
          const blur = new cv.Mat();
          const edges = new cv.Mat();
          const contours = new cv.MatVector();
          const hierarchy = new cv.Mat();

          // Convert to grayscale
          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
          
          // Apply Gaussian blur
          cv.GaussianBlur(gray, blur, new cv.Size(5, 5), 0);
          
          // Edge detection
          cv.Canny(blur, edges, 75, 200);
          
          // Find contours
          cv.findContours(edges, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
          
          let bestContour = null;
          let maxArea = 0;
          
          // Find the largest rectangular contour
          for (let i = 0; i < contours.size(); i++) {
            const contour = contours.get(i);
            const area = cv.contourArea(contour);
            
            if (area > 1000) { // Minimum area threshold
              const peri = cv.arcLength(contour, true);
              const approx = new cv.Mat();
              cv.approxPolyDP(contour, approx, 0.02 * peri, true);
              
              if (approx.rows === 4 && area > maxArea) {
                maxArea = area;
                if (bestContour) bestContour.delete();
                bestContour = approx.clone();
              }
              approx.delete();
            }
          }
          
          // Clean up
          src.delete();
          gray.delete();
          blur.delete();
          edges.delete();
          contours.delete();
          hierarchy.delete();
          
          return bestContour;
        } catch (err) {
          console.error('Detection error:', err);
          return null;
        }
      }

      getCornerPoints(contour) {
        if (!contour || contour.rows !== 4) return null;
        
        const points = [];
        for (let i = 0; i < 4; i++) {
          const point = contour.data32S.slice(i * 2, i * 2 + 2);
          points.push({ x: point[0], y: point[1] });
        }
        
        // Sort points: top-left, top-right, bottom-right, bottom-left
        points.sort((a, b) => a.y - b.y);
        const top = points.slice(0, 2).sort((a, b) => a.x - b.x);
        const bottom = points.slice(2, 4).sort((a, b) => a.x - b.x);
        
        return [top[0], top[1], bottom[1], bottom[0]];
      }
    }

    const detector = new CustomDocumentDetector();

    function updateStatus(message, type = 'loading') {
      const el = document.getElementById('statusMessage');
      el.textContent = message;
      el.className = `status ${type}`;
    }

    async function onOpenCvReady() {
      try {
        window.cv = await window.cv;
        updateStatus("OpenCV ready. Initializing detector...", 'ready');
        
        if (detector.init()) {
          await startCamera();
          setupOverlay();
          updateStatus("Ready! Click 'Start Detection' for real-time scanning.", 'ready');
          document.getElementById("cameraSection").style.display = "block";
          document.getElementById("fileInput").disabled = false;
          document.getElementById("captureBtn").disabled = false;
          document.getElementById("detectionToggle").disabled = false;
        } else {
          updateStatus("Failed to initialize detector");
        }
      } catch (err) {
        updateStatus("OpenCV init failed: " + err);
      }
    }

    function setupOverlay() {
      video = document.getElementById('videoElement');
      overlayCanvas = document.getElementById('overlayCanvas');
      overlayCtx = overlayCanvas.getContext('2d');
      
      // Sync overlay canvas size with video
      video.addEventListener('loadedmetadata', () => {
        overlayCanvas.width = video.videoWidth;
        overlayCanvas.height = video.videoHeight;
      });
    }

    function startRealtimeDetection() {
      if (isDetecting) return;
      
      isDetecting = true;
      updateStatus("Real-time detection active", 'detecting');
      document.getElementById('detectionToggle').textContent = '‚èπÔ∏è Stop Detection';
      
      const processFrame = () => {
        if (!isDetecting) return;
        
        try {
          // Create temporary canvas for processing
          const tempCanvas = document.createElement('canvas');
          const tempCtx = tempCanvas.getContext('2d');
          tempCanvas.width = video.videoWidth;
          tempCanvas.height = video.videoHeight;
          
          // Draw current video frame
          tempCtx.drawImage(video, 0, 0);
          
          // Detect document
          const contour = detector.detectDocument(tempCanvas);
          
          // Clear overlay
          overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
          
          if (contour) {
            const points = detector.getCornerPoints(contour);
            if (points && points.length === 4) {
              // Scale points to overlay canvas size
              const scaleX = overlayCanvas.width / tempCanvas.width;
              const scaleY = overlayCanvas.height / tempCanvas.height;
              
              overlayCtx.strokeStyle = 'lime';
              overlayCtx.lineWidth = 4;
              overlayCtx.shadowBlur = 10;
              overlayCtx.shadowColor = 'black';
              
              overlayCtx.beginPath();
              overlayCtx.moveTo(points[0].x * scaleX, points[0].y * scaleY);
              for (let i = 1; i < 4; i++) {
                overlayCtx.lineTo(points[i].x * scaleX, points[i].y * scaleY);
              }
              overlayCtx.closePath();
              overlayCtx.stroke();
              
              // Draw corner dots
              overlayCtx.fillStyle = 'red';
              overlayCtx.shadowBlur = 5;
              points.forEach(point => {
                overlayCtx.beginPath();
                overlayCtx.arc(point.x * scaleX, point.y * scaleY, 8, 0, 2 * Math.PI);
                overlayCtx.fill();
              });
            }
            contour.delete();
          }
          
          // Update FPS counter
          frameCount++;
          const now = performance.now();
          if (now - lastFpsTime >= 1000) {
            document.getElementById('fpsCounter').textContent = `${frameCount} FPS`;
            frameCount = 0;
            lastFpsTime = now;
          }
          
        } catch (err) {
          console.error('Frame processing error:', err);
        }
        
        detectionLoop = requestAnimationFrame(processFrame);
      };
      
      processFrame();
    }

    function stopRealtimeDetection() {
      isDetecting = false;
      if (detectionLoop) {
        cancelAnimationFrame(detectionLoop);
        detectionLoop = null;
      }
      
      // Clear overlay
      if (overlayCtx) {
        overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
      }
      
      updateStatus("Real-time detection stopped", 'ready');
      document.getElementById('detectionToggle').textContent = 'üîç Start Detection';
      document.getElementById('fpsCounter').textContent = '0 FPS';
    }

    async function startCamera() {
      try {
        if (videoStream) videoStream.getTracks().forEach(track => track.stop());

        const constraints = {
          video: {
            facingMode: currentCamera,
            width: { ideal: 1280 },
            height: { ideal: 720 },
            advanced: [{ torch: flashOn }]
          }
        };

        videoStream = await navigator.mediaDevices.getUserMedia(constraints);
        const video = document.getElementById('videoElement');
        video.srcObject = videoStream;

        const [track] = videoStream.getVideoTracks();
        imageCapture = new ImageCapture(track);
        document.getElementById("flashToggleBtn").disabled = false;
      } catch (err) {
        alert("Camera error: " + err);
      }
    }

    document.getElementById("detectionToggle").addEventListener("click", () => {
      if (isDetecting) {
        stopRealtimeDetection();
      } else {
        startRealtimeDetection();
      }
    });

    document.getElementById("flashToggleBtn").addEventListener("click", async () => {
      if (!imageCapture || !imageCapture.track.getCapabilities().torch) {
        alert("Flash not supported on this device.");
        return;
      }
      flashOn = !flashOn;
      try {
        await imageCapture.track.applyConstraints({ advanced: [{ torch: flashOn }] });
        document.getElementById("flashToggleBtn").textContent = flashOn ? "üí° Flash On" : "üí° Flash Off";
      } catch (err) {
        console.error("Flash toggle failed:", err);
      }
    });

    function captureImage() {
      const video = document.getElementById("videoElement");
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext("2d").drawImage(video, 0, 0);
      canvas.toBlob(blob => {
        const img = new Image();
        img.onload = () => {
          lastImage = img;
          processImage(img);
        };
        img.src = URL.createObjectURL(blob);
      });
    }

    function processImage(img) {
      const t0 = performance.now();
      document.getElementById("originalImage").src = img.src;

      // Create processing canvas
      const processCanvas = document.createElement('canvas');
      processCanvas.width = img.width;
      processCanvas.height = img.height;
      const processCtx = processCanvas.getContext('2d');
      processCtx.drawImage(img, 0, 0);

      // Detect and highlight document
      const contour = detector.detectDocument(processCanvas);
      if (contour) {
        const points = detector.getCornerPoints(contour);
        if (points && points.length === 4) {
          processCtx.strokeStyle = 'lime';
          processCtx.lineWidth = 4;
          processCtx.beginPath();
          processCtx.moveTo(points[0].x, points[0].y);
          for (let i = 1; i < 4; i++) {
            processCtx.lineTo(points[i].x, points[i].y);
          }
          processCtx.closePath();
          processCtx.stroke();
        }
        contour.delete();
      }

      const contrastCanvas = enhanceContrast(processCanvas);

      const outCanvas = document.getElementById("resultCanvas");
      outCanvas.width = contrastCanvas.width;
      outCanvas.height = contrastCanvas.height;
      outCanvas.getContext("2d").drawImage(contrastCanvas, 0, 0);

      document.getElementById("resultsSection").style.display = "block";
      document.getElementById("reprocessBtn").disabled = false;

      const t1 = performance.now();
      document.getElementById("perfMetric").textContent = `Processing Time: ${(t1 - t0).toFixed(2)} ms`;

      performOCR(outCanvas);
    }

    function enhanceContrast(canvas) {
      const src = cv.imread(canvas);
      let ycrcb = new cv.Mat();
      cv.cvtColor(src, ycrcb, cv.COLOR_RGBA2YCrCb);

      let channels = new cv.MatVector();
      cv.split(ycrcb, channels);
      let clahe = new cv.CLAHE(2.0, new cv.Size(8, 8));
      clahe.apply(channels.get(0), channels.get(0));
      cv.merge(channels, ycrcb);

      let dst = new cv.Mat();
      cv.cvtColor(ycrcb, dst, cv.COLOR_YCrCb2RGBA);
      cv.imshow(canvas, dst);

      src.delete(); ycrcb.delete(); dst.delete(); channels.delete(); clahe.delete();
      return canvas;
    }

    async function performOCR(canvas) {
      document.getElementById("ocrResult").textContent = "üîç Recognizing text...";
      try {
        const { data: { text } } = await Tesseract.recognize(canvas, 'eng', {
          logger: m => console.log(m)
        });
        document.getElementById("ocrResult").textContent = text.trim() || "No text found.";
      } catch (err) {
        document.getElementById("ocrResult").textContent = "‚ö†Ô∏è OCR failed.";
        console.error(err);
      }
    }

    function newScan() {
      stopRealtimeDetection();
      document.getElementById("resultsSection").style.display = "none";
      document.getElementById("ocrResult").textContent = "No text extracted yet.";
      document.getElementById("reprocessBtn").disabled = true;
      lastImage = null;
    }

    // Event listeners
    document.getElementById("captureBtn").addEventListener("click", captureImage);
    document.getElementById("reprocessBtn").addEventListener("click", () => {
      if (lastImage) processImage(lastImage);
    });
    document.getElementById("newScanBtn").addEventListener("click", newScan);
    document.getElementById("fileInput").addEventListener("change", e => {
      const file = e.target.files[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = ev => {
        const img = new Image();
        img.onload = () => {
          lastImage = img;
          processImage(img);
        };
        img.src = ev.target.result;
      };
      reader.readAsDataURL(file);
    });

    // Cleanup on page unload
    window.addEventListener('beforeunload', () => {
      stopRealtimeDetection();
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop());
      }
    });
  </script>

  <script src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5.0.4/dist/tesseract.min.js"></script>
</body>
</html>