<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLO Real-Time Object Detection</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: #1a1a1a;
            color: #fff;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }

        h1 {
            margin-bottom: 20px;
            color: #00ff88;
        }

        .container {
            max-width: 1200px;
            width: 100%;
        }

        .controls {
            background: #2a2a2a;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
            align-items: center;
        }

        button {
            background: #00ff88;
            color: #000;
            border: none;
            padding: 12px 24px;
            border-radius: 5px;
            cursor: pointer;
            font-weight: bold;
            font-size: 14px;
            transition: all 0.3s;
        }

        button:hover {
            background: #00dd77;
            transform: translateY(-2px);
        }

        button:disabled {
            background: #555;
            cursor: not-allowed;
            transform: none;
        }

        .stats {
            background: #2a2a2a;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
        }

        .stat-item {
            background: #1a1a1a;
            padding: 10px;
            border-radius: 5px;
            border-left: 3px solid #00ff88;
        }

        .stat-label {
            font-size: 12px;
            color: #888;
            margin-bottom: 5px;
        }

        .stat-value {
            font-size: 24px;
            font-weight: bold;
            color: #00ff88;
        }

        .canvas-container {
            position: relative;
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 10px 40px rgba(0, 255, 136, 0.3);
        }

        #videoElement {
            width: 100%;
            height: auto;
            display: block;
        }

        #canvasElement {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        .status {
            margin-top: 20px;
            padding: 15px;
            background: #2a2a2a;
            border-radius: 10px;
            text-align: center;
        }

        .loading {
            color: #ffaa00;
        }

        .ready {
            color: #00ff88;
        }

        .error {
            color: #ff4444;
        }

        select {
            background: #1a1a1a;
            color: #fff;
            border: 2px solid #00ff88;
            padding: 10px;
            border-radius: 5px;
            font-size: 14px;
            cursor: pointer;
        }

        .inference-history {
            background: #2a2a2a;
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
            max-height: 200px;
            overflow-y: auto;
        }

        .inference-entry {
            padding: 8px;
            margin: 5px 0;
            background: #1a1a1a;
            border-radius: 5px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .inference-time {
            color: #00ff88;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéØ YOLO Real-Time Object Detection</h1>
        
        <div class="controls">
            <button id="startBtn">Start Camera</button>
            <button id="stopBtn" disabled>Stop Camera</button>
            <button id="detectBtn" disabled>Start Detection</button>
            <button id="pauseBtn" disabled>Pause Detection</button>
            
            <select id="modelSelect">
                <option value="yolov12n">YOLOv12n (Nano)</option>
            </select>
        </div>

        <div class="stats">
            <div class="stat-item">
                <div class="stat-label">Inference Time</div>
                <div class="stat-value" id="inferenceTime">0 ms</div>
            </div>
            <div class="stat-item">
                <div class="stat-label">FPS</div>
                <div class="stat-value" id="fps">0</div>
            </div>
            <div class="stat-item">
                <div class="stat-label">Objects Detected</div>
                <div class="stat-value" id="objectCount">0</div>
            </div>
            <div class="stat-item">
                <div class="stat-label">Total Inferences</div>
                <div class="stat-value" id="totalInferences">0</div>
            </div>
        </div>

        <div class="canvas-container">
            <video id="videoElement" autoplay playsinline></video>
            <canvas id="canvasElement"></canvas>
        </div>

        <div class="status" id="status">
            <span class="loading">‚è≥ Initializing...</span>
        </div>

        <div class="inference-history" id="inferenceHistory">
            <h3 style="margin-bottom: 10px;">Recent Inference Times</h3>
        </div>
    </div>

    <!-- Load ONNX Runtime Web - Updated to latest version for better compatibility -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.1/dist/ort.min.js">

    <script>
        // Configuration
        const CONFIG = {
            modelInputSize: 640,
            confidenceThreshold: 0.45,
            iouThreshold: 0.45,
            maxDetections: 100,
        };

        // COCO class names
        const CLASS_NAMES = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
            'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
            'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
            'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
            'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ];

        // State
        let stream = null;
        let session = null;
        let isDetecting = false;
        let animationFrameId = null;
        let totalInferences = 0;
        let inferenceHistory = [];

        // DOM Elements
        const videoElement = document.getElementById('videoElement');
        const canvasElement = document.getElementById('canvasElement');
        const ctx = canvasElement.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const detectBtn = document.getElementById('detectBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const modelSelect = document.getElementById('modelSelect');
        const statusElement = document.getElementById('status');

        // Update status
        function updateStatus(message, className = 'loading') {
            statusElement.innerHTML = `<span class="${className}">${message}</span>`;
        }

        // Initialize ONNX Runtime
        async function initializeModel() {
            try {
                updateStatus('‚è≥ Loading YOLO model...', 'loading');
                
                // Configure ONNX Runtime for optimal performance
                ort.env.wasm.numThreads = 4;
                ort.env.wasm.simd = true;
                ort.env.wasm.proxy = false;  // Disable proxy mode for better compatibility

                const modelPath = 'yolov12n.onnx';

                console.log('Loading YOLOv12n model from:', modelPath);

                // Create session with WASM backend (most compatible)
                session = await ort.InferenceSession.create(modelPath, {
                    executionProviders: ['wasm'],
                    graphOptimizationLevel: 'all',
                    enableCpuMemArena: true,
                    enableMemPattern: true,
                    executionMode: 'sequential'
                });
                
                updateStatus('‚úÖ Model loaded successfully!', 'ready');
                detectBtn.disabled = false;
                return true;
            } catch (error) {
                console.error('Model loading error:', error);
                updateStatus(`‚ùå Error loading model: ${error.message}. Make sure yolov8n.onnx is in the same directory!`, 'error');
                return false;
            }
        }

        // Start camera
        async function startCamera() {
            try {
                updateStatus('‚è≥ Starting camera...', 'loading');
                
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'environment'
                    }
                });
                
                videoElement.srcObject = stream;
                
                videoElement.onloadedmetadata = () => {
                    canvasElement.width = videoElement.videoWidth;
                    canvasElement.height = videoElement.videoHeight;
                    updateStatus('‚úÖ Camera started!', 'ready');
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    
                    // Initialize model after camera starts
                    if (!session) {
                        initializeModel();
                    }
                };
            } catch (error) {
                console.error('Camera error:', error);
                updateStatus(`‚ùå Error accessing camera: ${error.message}`, 'error');
            }
        }

        // Stop camera
        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
                videoElement.srcObject = null;
                startBtn.disabled = false;
                stopBtn.disabled = true;
                detectBtn.disabled = true;
                pauseBtn.disabled = true;
                updateStatus('Camera stopped', 'ready');
            }
        }

        // Preprocess image for YOLO
        function preprocessImage(video) {
            const inputSize = CONFIG.modelInputSize;
            
            // Create temporary canvas for preprocessing
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = inputSize;
            tempCanvas.height = inputSize;
            const tempCtx = tempCanvas.getContext('2d');
            
            // Draw and resize
            tempCtx.drawImage(video, 0, 0, inputSize, inputSize);
            
            // Get image data
            const imageData = tempCtx.getImageData(0, 0, inputSize, inputSize);
            const pixels = imageData.data;
            
            // Convert to RGB float array (normalize to 0-1)
            const inputArray = new Float32Array(3 * inputSize * inputSize);
            
            for (let i = 0; i < inputSize * inputSize; i++) {
                inputArray[i] = pixels[i * 4] / 255.0;                    // R
                inputArray[inputSize * inputSize + i] = pixels[i * 4 + 1] / 255.0;     // G
                inputArray[2 * inputSize * inputSize + i] = pixels[i * 4 + 2] / 255.0; // B
            }
            
            return inputArray;
        }

        // Non-Maximum Suppression
        function nms(boxes, confidences, iouThreshold) {
            const indices = Array.from({ length: boxes.length }, (_, i) => i);
            indices.sort((a, b) => confidences[b] - confidences[a]);
            
            const keep = [];
            
            while (indices.length > 0) {
                const current = indices[0];
                keep.push(current);
                indices.shift();
                
                const filtered = [];
                for (const index of indices) {
                    const iou = calculateIoU(boxes[current], boxes[index]);
                    if (iou < iouThreshold) {
                        filtered.push(index);
                    }
                }
                indices.length = 0;
                indices.push(...filtered);
            }
            
            return keep;
        }

        // Calculate Intersection over Union
        function calculateIoU(box1, box2) {
            const x1 = Math.max(box1[0], box2[0]);
            const y1 = Math.max(box1[1], box2[1]);
            const x2 = Math.min(box1[2], box2[2]);
            const y2 = Math.min(box1[3], box2[3]);
            
            const intersection = Math.max(0, x2 - x1) * Math.max(0, y2 - y1);
            const area1 = (box1[2] - box1[0]) * (box1[3] - box1[1]);
            const area2 = (box2[2] - box2[0]) * (box2[3] - box2[1]);
            const union = area1 + area2 - intersection;
            
            return intersection / union;
        }

        // Process model output
        function processOutput(output, videoWidth, videoHeight) {
            const boxes = [];
            const confidences = [];
            const classIds = [];
            
            // YOLOv8 output shape: [1, 84, 8400]
            // Format: [x_center, y_center, width, height, class0_conf, class1_conf, ...]
            const data = output.data;
            const numDetections = output.dims[2];
            const numClasses = 80;
            
            for (let i = 0; i < numDetections; i++) {
                // Get class confidences (indices 4-83)
                let maxConf = 0;
                let maxClassId = 0;
                
                for (let j = 0; j < numClasses; j++) {
                    const conf = data[i + (4 + j) * numDetections];
                    if (conf > maxConf) {
                        maxConf = conf;
                        maxClassId = j;
                    }
                }
                
                if (maxConf > CONFIG.confidenceThreshold) {
                    const xCenter = data[i];
                    const yCenter = data[i + numDetections];
                    const width = data[i + 2 * numDetections];
                    const height = data[i + 3 * numDetections];
                    
                    // Convert to x1, y1, x2, y2
                    const x1 = (xCenter - width / 2) * videoWidth / CONFIG.modelInputSize;
                    const y1 = (yCenter - height / 2) * videoHeight / CONFIG.modelInputSize;
                    const x2 = (xCenter + width / 2) * videoWidth / CONFIG.modelInputSize;
                    const y2 = (yCenter + height / 2) * videoHeight / CONFIG.modelInputSize;
                    
                    boxes.push([x1, y1, x2, y2]);
                    confidences.push(maxConf);
                    classIds.push(maxClassId);
                }
            }
            
            // Apply NMS
            const keepIndices = nms(boxes, confidences, CONFIG.iouThreshold);
            
            return keepIndices.map(i => ({
                box: boxes[i],
                confidence: confidences[i],
                classId: classIds[i],
                className: CLASS_NAMES[classIds[i]]
            }));
        }

        // Draw detections
        function drawDetections(detections) {
            ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            
            detections.forEach(detection => {
                const [x1, y1, x2, y2] = detection.box;
                const width = x2 - x1;
                const height = y2 - y1;
                
                // Draw box
                ctx.strokeStyle = '#00ff88';
                ctx.lineWidth = 3;
                ctx.strokeRect(x1, y1, width, height);
                
                // Draw label background
                const label = `${detection.className} ${(detection.confidence * 100).toFixed(1)}%`;
                ctx.font = 'bold 16px Arial';
                const textWidth = ctx.measureText(label).width;
                ctx.fillStyle = '#00ff88';
                ctx.fillRect(x1, y1 - 25, textWidth + 10, 25);
                
                // Draw label text
                ctx.fillStyle = '#000';
                ctx.fillText(label, x1 + 5, y1 - 7);
            });
            
            // Update object count
            document.getElementById('objectCount').textContent = detections.length;
        }

        // Add inference time to history
        function addInferenceToHistory(time) {
            inferenceHistory.unshift(time);
            if (inferenceHistory.length > 20) {
                inferenceHistory.pop();
            }
            
            // Update history display
            const historyDiv = document.getElementById('inferenceHistory');
            const entriesHTML = inferenceHistory.map((t, i) => `
                <div class="inference-entry">
                    <span>Inference #${totalInferences - i}</span>
                    <span class="inference-time">${t}ms</span>
                </div>
            `).join('');
            
            historyDiv.innerHTML = `<h3 style="margin-bottom: 10px;">Recent Inference Times</h3>${entriesHTML}`;
        }

        // Detection loop
        async function detect() {
            if (!isDetecting || !session) return;
            
            const startTime = performance.now();
            
            try {
                // Preprocess
                const inputData = preprocessImage(videoElement);
                const tensor = new ort.Tensor('float32', inputData, [1, 3, CONFIG.modelInputSize, CONFIG.modelInputSize]);
                
                // Run inference
                const inferenceStart = performance.now();
                const results = await session.run({ images: tensor });
                const inferenceTime = Math.round(performance.now() - inferenceStart);
                
                // Process output
                const output = results.output0;
                const detections = processOutput(output, videoElement.videoWidth, videoElement.videoHeight);
                
                // Draw results
                drawDetections(detections);
                
                // Update stats
                totalInferences++;
                document.getElementById('inferenceTime').textContent = `${inferenceTime} ms`;
                document.getElementById('totalInferences').textContent = totalInferences;
                addInferenceToHistory(inferenceTime);
                
                // Calculate FPS
                const totalTime = performance.now() - startTime;
                const fps = Math.round(1000 / totalTime);
                document.getElementById('fps').textContent = fps;
                
            } catch (error) {
                console.error('Detection error:', error);
                updateStatus(`‚ùå Detection error: ${error.message}`, 'error');
            }
            
            // Continue loop
            if (isDetecting) {
                animationFrameId = requestAnimationFrame(detect);
            }
        }

        // Start detection
        function startDetection() {
            if (!session) {
                alert('Model not loaded yet. Please wait.');
                return;
            }
            
            isDetecting = true;
            detectBtn.disabled = true;
            pauseBtn.disabled = false;
            updateStatus('üîç Detecting objects...', 'ready');
            detect();
        }

        // Pause detection
        function pauseDetection() {
            isDetecting = false;
            detectBtn.disabled = false;
            pauseBtn.disabled = true;
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
            updateStatus('‚è∏Ô∏è Detection paused', 'ready');
        }

        // Event listeners
        startBtn.addEventListener('click', startCamera);
        stopBtn.addEventListener('click', () => {
            stopCamera();
            pauseDetection();
        });
        detectBtn.addEventListener('click', startDetection);
        pauseBtn.addEventListener('click', pauseDetection);

        // Initialize on load
        window.addEventListener('load', () => {
            updateStatus('üëã Ready! Click "Start Camera" to begin', 'ready');
        });
    </script>
</body>
</html>